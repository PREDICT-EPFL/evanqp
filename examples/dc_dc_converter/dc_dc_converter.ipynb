{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "diverse-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "warming-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import polytope as pc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from evanqp import CvxpyProblem, MPCProblem, Polytope, RandomSampler, FFNN, Verifier\n",
    "from evanqp.layers import BoundArithmetic, BaseLayer, SeqLayer, LinearLayer, ReluLayer, QPLayer\n",
    "from utils import dlqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "crucial-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(4)\n",
    "np.random.seed(4)\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "import latexify\n",
    "latexify.latexify(fig_width=3.39/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "french-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCDCConverter(MPCProblem):\n",
    "    def __init__(self, N=10):\n",
    "        self.N = N\n",
    "\n",
    "        n = 2\n",
    "        m = 1\n",
    "\n",
    "        # Linearized dynamics\n",
    "        self.A = np.array([[0.971356387900839, -0.009766890567613], [1.731870774203751, 0.970462385352837]])\n",
    "        self.B = np.array([[0.148778899882612], [0.180827260808426]])\n",
    "        self.C = np.array([[0, 1]])\n",
    "        \n",
    "        # Steady state\n",
    "        ref = 5.0\n",
    "        ss = np.linalg.solve(np.block([[self.A - np.eye(n), self.B],[self.C, 0]]), np.array([0, 0, ref]))\n",
    "        self.xs = ss[0:2]\n",
    "        self.us = ss[2:3]\n",
    "\n",
    "        # Weights\n",
    "        self.Q = np.diag([90, 1])\n",
    "        self.R = np.array([[1]])\n",
    "        self.K, self.P, _ = dlqr(self.A, self.B, self.Q, self.R)\n",
    "        \n",
    "        # Constraints\n",
    "        self.x_max = np.array([0.2, 7.0])\n",
    "        self.x_min = np.array([0.0, 0.0])\n",
    "        self.u_max = np.array([1.0])\n",
    "        self.u_min = np.array([0.0])\n",
    "        \n",
    "        # Terminal Set computation (shifted)\n",
    "        # state constraints\n",
    "        Hx = np.vstack((np.eye(n), -np.eye(n)))\n",
    "        hx = np.concatenate((self.x_max-self.xs, -(self.x_min-self.xs)))\n",
    "        # input constraints\n",
    "        Hu = np.vstack((np.eye(m), -np.eye(m)))\n",
    "        hu = np.concatenate((self.u_max-self.us, -(self.u_min-self.us)))\n",
    "        # closed loop dynamics\n",
    "        Ak = self.A - self.B @ self.K\n",
    "        # state & input constraints\n",
    "        HH = np.vstack((Hx, -Hu @ self.K))\n",
    "        hh = np.concatenate((hx, hu))\n",
    "        # compute maximal invariant set\n",
    "        O = pc.Polytope(HH, hh)\n",
    "        while True:\n",
    "            O_prev = O\n",
    "            # pre-set\n",
    "            O = O.intersect(pc.Polytope(O.A @ Ak, O.b))\n",
    "            if O == O_prev:\n",
    "                break\n",
    "        self.F, self.f = O.A, O.b\n",
    "\n",
    "        self.x0 = cp.Parameter(n, name='x0')\n",
    "        self.x = cp.Variable((N + 1, n), name='x')\n",
    "        self.u0 = cp.Variable(m, name='u0')\n",
    "        self.u = cp.Variable((N, m), name='u')\n",
    "\n",
    "        objective = cp.quad_form(self.x[N, :] - self.xs, self.P)\n",
    "        constraints = [self.x0 == self.x[0, :], self.u0 == self.u[0, :]]\n",
    "\n",
    "        for i in range(N):\n",
    "            objective += cp.quad_form(self.x[i, :] - self.xs, self.Q) + cp.quad_form(self.u[i, :] - self.us, self.R)\n",
    "            constraints += [self.x[i + 1, :] == self.A @ self.x[i, :] + self.B @ self.u[i, :]]\n",
    "            constraints += [self.x_min <= self.x[i, :], self.x[i, :] <= self.x_max]\n",
    "            constraints += [self.u_min <= self.u[i, :], self.u[i, :] <= self.u_max]\n",
    "        constraints += [self.F @ (self.x[N, :] - self.xs) <= self.f]\n",
    "\n",
    "        self.objective = cp.Minimize(objective)\n",
    "        self.prob = cp.Problem(self.objective, constraints)\n",
    "\n",
    "    def problem(self):\n",
    "        return self.prob\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.x0]\n",
    "\n",
    "    def variables(self):\n",
    "        return [self.u0]\n",
    "\n",
    "    def solve(self, x0):\n",
    "        self.x0.value = x0\n",
    "        try:\n",
    "            self.prob.solve(solver=cp.GUROBI)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        solution = {self.u0: self.u0.value,\n",
    "                    self.u: self.u.value,\n",
    "                    self.x: self.x.value,\n",
    "                    self.objective: self.objective.value}\n",
    "        return solution\n",
    "\n",
    "    def reduced_objective(self):\n",
    "        objective = cp.quad_form(self.x[self.N, :] - self.xs, self.P)\n",
    "        for i in range(1, self.N):\n",
    "            objective += cp.quad_form(self.x[i, :] - self.xs, self.Q) + cp.quad_form(self.u[i, :] - self.us, self.R)\n",
    "        return cp.Minimize(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wanted-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpc_controller = DCDCConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "external-sharp",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2022-12-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [01:17<00:08,  1.17it/s]/usr/local/lib/python3.8/site-packages/cvxpy/problems/problem.py:1278: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "100%|██████████| 100/100 [01:23<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.linspace(0, 0.2, 100)\n",
    "x2 = np.linspace(0, 7, 100)\n",
    "x, y = np.meshgrid(x1, x2)\n",
    "z_opt = np.zeros(x.shape)\n",
    "for i in tqdm(range(x.shape[0])):\n",
    "    for j in range(x.shape[1]):\n",
    "        sol = mpc_controller.solve(np.array([x[i, j], y[i, j]]))\n",
    "        u0 = sol[mpc_controller.variables()[0]]\n",
    "        z_opt[i, j] = u0 if u0 is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metropolitan-brunswick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 122.04x75.4249 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cs = ax.contourf(x, y, z_opt, levels=100)\n",
    "for c in cs.collections:\n",
    "    c.set_edgecolor('face')\n",
    "fig.colorbar(cs, ticks=[0, 0.25, 0.5, 0.75, 1])\n",
    "ax.set_title('Original Controller')\n",
    "ax.set_xlabel(r'$i_L$')\n",
    "ax.set_ylabel(r'$v_O$')\n",
    "plt.savefig('figures/original.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "removed-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_set = Polytope(np.vstack((np.eye(2), -np.eye(2))), np.concatenate((mpc_controller.x_max, -mpc_controller.x_min)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "directed-latitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/5000 [00:00<01:05, 76.12it/s]/usr/local/lib/python3.8/site-packages/cvxpy/problems/problem.py:1278: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "100%|██████████| 5000/5000 [00:47<00:00, 104.53it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler = RandomSampler(mpc_controller, parameter_set)\n",
    "parameter_samples, variable_samples = sampler.sample(5000, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adjustable-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_samples = torch.from_numpy(parameter_samples).float()\n",
    "variable_samples  = torch.from_numpy(variable_samples).float()\n",
    "\n",
    "torch.save(parameter_samples, 'parameter_samples.pt')\n",
    "torch.save(variable_samples, 'variable_samples.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "absolute-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_samples = torch.load('parameter_samples.pt')\n",
    "variable_samples  = torch.load('variable_samples.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "blind-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCDCConverterDataset(Dataset):\n",
    "    def __init__(self, parameter_samples, variable_samples):\n",
    "        self.parameter_samples = parameter_samples\n",
    "        self.variable_samples = variable_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.parameter_samples.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.parameter_samples[idx, :], self.variable_samples[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "immediate-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DCDCConverterDataset(parameter_samples, variable_samples)\n",
    "\n",
    "seed = 1\n",
    "train_set_ratio = 0.8\n",
    "\n",
    "train_set_size = int(len(dataset) * train_set_ratio)\n",
    "test_set_size = len(dataset) - train_set_size\n",
    "train_set, test_set = random_split(dataset, [train_set_size, test_set_size], generator=torch.Generator().manual_seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "complicated-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QPLayerProblem(CvxpyProblem):\n",
    "    def __init__(self, H, nz, eps=1e-4):\n",
    "        self.z = cp.Variable(nz)\n",
    "        self.x = cp.Parameter(nz)\n",
    "        self.prob = cp.Problem(cp.Minimize(cp.sum_squares(H @ self.z + self.x) + eps * cp.sum_squares(self.z)), [self.z >= 0])\n",
    "        \n",
    "    def problem(self):\n",
    "        return self.prob\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.x]\n",
    "\n",
    "    def variables(self):\n",
    "        return [self.z]\n",
    "    \n",
    "    def solve(self, x):\n",
    "        self.x.value = x\n",
    "        self.prob.solve(solver=cp.GUROBI)\n",
    "\n",
    "        solution = {self.z: self.z.value}\n",
    "        return solution\n",
    "\n",
    "\n",
    "class QPModule(nn.Module):\n",
    "    def __init__(self, nz, eps=1e-4):\n",
    "        super(QPModule, self).__init__()\n",
    "        self.H = nn.Parameter(torch.randn(nz, nz))\n",
    "        self.nz = nz\n",
    "        self.eps = eps\n",
    "        H = cp.Parameter((nz, nz))\n",
    "        prob = QPLayerProblem(H, nz, eps)\n",
    "        self.layer = CvxpyLayer(prob.problem(), [H] + prob.parameters(), prob.variables())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(self.H, x, solver_args={'solve_method':'ECOS'})[0]\n",
    "        \n",
    "    def milp_layer(self, depth):\n",
    "        prob = QPLayerProblem(self.H.detach().cpu().numpy(), self.nz, self.eps)\n",
    "        return QPLayer(prob, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "infrared-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatModule(nn.Module):\n",
    "    def __init__(self, num_features, x_min, x_max):\n",
    "        super(SatModule, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.max(torch.min(x, torch.from_numpy(self.x_max).float()), torch.from_numpy(self.x_min).float())\n",
    "    \n",
    "    def milp_layer(self, depth):\n",
    "        return SeqLayer([\n",
    "            LinearLayer(np.eye(self.num_features), -self.x_min, depth),\n",
    "            ReluLayer(self.num_features, depth),\n",
    "            LinearLayer(np.eye(self.num_features), self.x_min, depth),\n",
    "            LinearLayer(-np.eye(self.num_features), self.x_max, depth),\n",
    "            ReluLayer(self.num_features, depth),\n",
    "            LinearLayer(-np.eye(self.num_features), self.x_max, depth)\n",
    "        ], depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "minute-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 3\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(mpc_controller.parameter_size(), nz),\n",
    "    QPModule(nz),\n",
    "    nn.Linear(nz, mpc_controller.variable_size()),\n",
    "    # SatModule(mpc_controller.variable_size(), mpc_controller.u_min, mpc_controller.u_max)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "native-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(model, data, target):\n",
    "    output = model(data)\n",
    "    loss = F.mse_loss(output, target)\n",
    "    loss += 1e2 / len(data) * F.mse_loss(model(torch.from_numpy(mpc_controller.xs).float().to(data.device)), torch.from_numpy(mpc_controller.us).float().to(data.device))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "configured-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(model, data, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data),\n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    train_loss /= len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "civil-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            test_loss += loss_function(model, data, target).item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print('Test set: Average loss: {:.6f}\\n'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "micro-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "train_kwargs = {'batch_size': 50}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "    \n",
    "train_loader = DataLoader(train_set, **train_kwargs)\n",
    "test_loader = DataLoader(test_set, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wicked-hungary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 0.810637\n",
      "Train Epoch: 1 [1000/4000 (25%)]\tLoss: 0.241078\n",
      "Train Epoch: 1 [2000/4000 (50%)]\tLoss: 0.172683\n",
      "Train Epoch: 1 [3000/4000 (75%)]\tLoss: 0.100165\n",
      "Test set: Average loss: 0.062774\n",
      "\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 0.070327\n",
      "Train Epoch: 2 [1000/4000 (25%)]\tLoss: 0.043823\n",
      "Train Epoch: 2 [2000/4000 (50%)]\tLoss: 0.041297\n",
      "Train Epoch: 2 [3000/4000 (75%)]\tLoss: 0.040310\n",
      "Test set: Average loss: 0.024074\n",
      "\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 0.028665\n",
      "Train Epoch: 3 [1000/4000 (25%)]\tLoss: 0.014248\n",
      "Train Epoch: 3 [2000/4000 (50%)]\tLoss: 0.013463\n",
      "Train Epoch: 3 [3000/4000 (75%)]\tLoss: 0.012999\n",
      "Test set: Average loss: 0.008199\n",
      "\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 0.009152\n",
      "Train Epoch: 4 [1000/4000 (25%)]\tLoss: 0.006976\n",
      "Train Epoch: 4 [2000/4000 (50%)]\tLoss: 0.006615\n",
      "Train Epoch: 4 [3000/4000 (75%)]\tLoss: 0.008353\n",
      "Test set: Average loss: 0.004899\n",
      "\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 0.004428\n",
      "Train Epoch: 5 [1000/4000 (25%)]\tLoss: 0.005916\n",
      "Train Epoch: 5 [2000/4000 (50%)]\tLoss: 0.006408\n",
      "Train Epoch: 5 [3000/4000 (75%)]\tLoss: 0.008534\n",
      "Test set: Average loss: 0.004838\n",
      "\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 0.004402\n",
      "Train Epoch: 6 [1000/4000 (25%)]\tLoss: 0.005839\n",
      "Train Epoch: 6 [2000/4000 (50%)]\tLoss: 0.006714\n",
      "Train Epoch: 6 [3000/4000 (75%)]\tLoss: 0.008674\n",
      "Test set: Average loss: 0.004783\n",
      "\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 0.003741\n",
      "Train Epoch: 7 [1000/4000 (25%)]\tLoss: 0.005804\n",
      "Train Epoch: 7 [2000/4000 (50%)]\tLoss: 0.006788\n",
      "Train Epoch: 7 [3000/4000 (75%)]\tLoss: 0.009050\n",
      "Test set: Average loss: 0.004831\n",
      "\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 0.003597\n",
      "Train Epoch: 8 [1000/4000 (25%)]\tLoss: 0.005613\n",
      "Train Epoch: 8 [2000/4000 (50%)]\tLoss: 0.006628\n",
      "Train Epoch: 8 [3000/4000 (75%)]\tLoss: 0.009219\n",
      "Test set: Average loss: 0.004787\n",
      "\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 0.003544\n",
      "Train Epoch: 9 [1000/4000 (25%)]\tLoss: 0.005467\n",
      "Train Epoch: 9 [2000/4000 (50%)]\tLoss: 0.006587\n",
      "Train Epoch: 9 [3000/4000 (75%)]\tLoss: 0.009182\n",
      "Test set: Average loss: 0.004726\n",
      "\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 0.003403\n",
      "Train Epoch: 10 [1000/4000 (25%)]\tLoss: 0.005359\n",
      "Train Epoch: 10 [2000/4000 (50%)]\tLoss: 0.006587\n",
      "Train Epoch: 10 [3000/4000 (75%)]\tLoss: 0.009044\n",
      "Test set: Average loss: 0.004664\n",
      "\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 0.003353\n",
      "Train Epoch: 11 [1000/4000 (25%)]\tLoss: 0.005329\n",
      "Train Epoch: 11 [2000/4000 (50%)]\tLoss: 0.006579\n",
      "Train Epoch: 11 [3000/4000 (75%)]\tLoss: 0.008967\n",
      "Test set: Average loss: 0.004640\n",
      "\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 0.003375\n",
      "Train Epoch: 12 [1000/4000 (25%)]\tLoss: 0.005320\n",
      "Train Epoch: 12 [2000/4000 (50%)]\tLoss: 0.006581\n",
      "Train Epoch: 12 [3000/4000 (75%)]\tLoss: 0.008805\n",
      "Test set: Average loss: 0.004599\n",
      "\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 0.003370\n",
      "Train Epoch: 13 [1000/4000 (25%)]\tLoss: 0.005312\n",
      "Train Epoch: 13 [2000/4000 (50%)]\tLoss: 0.006501\n",
      "Train Epoch: 13 [3000/4000 (75%)]\tLoss: 0.008834\n",
      "Test set: Average loss: 0.004572\n",
      "\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 0.003363\n",
      "Train Epoch: 14 [1000/4000 (25%)]\tLoss: 0.005274\n",
      "Train Epoch: 14 [2000/4000 (50%)]\tLoss: 0.006427\n",
      "Train Epoch: 14 [3000/4000 (75%)]\tLoss: 0.008871\n",
      "Test set: Average loss: 0.004572\n",
      "\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 0.003389\n",
      "Train Epoch: 15 [1000/4000 (25%)]\tLoss: 0.005227\n",
      "Train Epoch: 15 [2000/4000 (50%)]\tLoss: 0.006400\n",
      "Train Epoch: 15 [3000/4000 (75%)]\tLoss: 0.008837\n",
      "Test set: Average loss: 0.004567\n",
      "\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 0.003428\n",
      "Train Epoch: 16 [1000/4000 (25%)]\tLoss: 0.005299\n",
      "Train Epoch: 16 [2000/4000 (50%)]\tLoss: 0.006457\n",
      "Train Epoch: 16 [3000/4000 (75%)]\tLoss: 0.008403\n",
      "Test set: Average loss: 0.004533\n",
      "\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 0.003430\n",
      "Train Epoch: 17 [1000/4000 (25%)]\tLoss: 0.005447\n",
      "Train Epoch: 17 [2000/4000 (50%)]\tLoss: 0.006388\n",
      "Train Epoch: 17 [3000/4000 (75%)]\tLoss: 0.008191\n",
      "Test set: Average loss: 0.004503\n",
      "\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 0.003430\n",
      "Train Epoch: 18 [1000/4000 (25%)]\tLoss: 0.005525\n",
      "Train Epoch: 18 [2000/4000 (50%)]\tLoss: 0.006346\n",
      "Train Epoch: 18 [3000/4000 (75%)]\tLoss: 0.008003\n",
      "Test set: Average loss: 0.004537\n",
      "\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 0.003542\n",
      "Train Epoch: 19 [1000/4000 (25%)]\tLoss: 0.005410\n",
      "Train Epoch: 19 [2000/4000 (50%)]\tLoss: 0.006476\n",
      "Train Epoch: 19 [3000/4000 (75%)]\tLoss: 0.007833\n",
      "Test set: Average loss: 0.004509\n",
      "\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 0.003535\n",
      "Train Epoch: 20 [1000/4000 (25%)]\tLoss: 0.005393\n",
      "Train Epoch: 20 [2000/4000 (50%)]\tLoss: 0.006467\n",
      "Train Epoch: 20 [3000/4000 (75%)]\tLoss: 0.007788\n",
      "Test set: Average loss: 0.004471\n",
      "\n",
      "Train Epoch: 21 [0/4000 (0%)]\tLoss: 0.003508\n",
      "Train Epoch: 21 [1000/4000 (25%)]\tLoss: 0.005460\n",
      "Train Epoch: 21 [2000/4000 (50%)]\tLoss: 0.006374\n",
      "Train Epoch: 21 [3000/4000 (75%)]\tLoss: 0.007661\n",
      "Test set: Average loss: 0.004454\n",
      "\n",
      "Train Epoch: 22 [0/4000 (0%)]\tLoss: 0.003520\n",
      "Train Epoch: 22 [1000/4000 (25%)]\tLoss: 0.005448\n",
      "Train Epoch: 22 [2000/4000 (50%)]\tLoss: 0.006484\n",
      "Train Epoch: 22 [3000/4000 (75%)]\tLoss: 0.007528\n",
      "Test set: Average loss: 0.004478\n",
      "\n",
      "Train Epoch: 23 [0/4000 (0%)]\tLoss: 0.003584\n",
      "Train Epoch: 23 [1000/4000 (25%)]\tLoss: 0.005405\n",
      "Train Epoch: 23 [2000/4000 (50%)]\tLoss: 0.006398\n",
      "Train Epoch: 23 [3000/4000 (75%)]\tLoss: 0.007399\n",
      "Test set: Average loss: 0.004521\n",
      "\n",
      "Train Epoch: 24 [0/4000 (0%)]\tLoss: 0.003770\n",
      "Train Epoch: 24 [1000/4000 (25%)]\tLoss: 0.005360\n",
      "Train Epoch: 24 [2000/4000 (50%)]\tLoss: 0.006293\n",
      "Train Epoch: 24 [3000/4000 (75%)]\tLoss: 0.007038\n",
      "Test set: Average loss: 0.004486\n",
      "\n",
      "Train Epoch: 25 [0/4000 (0%)]\tLoss: 0.003725\n",
      "Train Epoch: 25 [1000/4000 (25%)]\tLoss: 0.005493\n",
      "Train Epoch: 25 [2000/4000 (50%)]\tLoss: 0.006242\n",
      "Train Epoch: 25 [3000/4000 (75%)]\tLoss: 0.006931\n",
      "Test set: Average loss: 0.004463\n",
      "\n",
      "Train Epoch: 26 [0/4000 (0%)]\tLoss: 0.003696\n",
      "Train Epoch: 26 [1000/4000 (25%)]\tLoss: 0.005515\n",
      "Train Epoch: 26 [2000/4000 (50%)]\tLoss: 0.006135\n",
      "Train Epoch: 26 [3000/4000 (75%)]\tLoss: 0.006871\n",
      "Test set: Average loss: 0.004458\n",
      "\n",
      "Train Epoch: 27 [0/4000 (0%)]\tLoss: 0.003741\n",
      "Train Epoch: 27 [1000/4000 (25%)]\tLoss: 0.005516\n",
      "Train Epoch: 27 [2000/4000 (50%)]\tLoss: 0.006042\n",
      "Train Epoch: 27 [3000/4000 (75%)]\tLoss: 0.006808\n",
      "Test set: Average loss: 0.004502\n",
      "\n",
      "Train Epoch: 28 [0/4000 (0%)]\tLoss: 0.003836\n",
      "Train Epoch: 28 [1000/4000 (25%)]\tLoss: 0.005384\n",
      "Train Epoch: 28 [2000/4000 (50%)]\tLoss: 0.005873\n",
      "Train Epoch: 28 [3000/4000 (75%)]\tLoss: 0.006654\n",
      "Test set: Average loss: 0.004486\n",
      "\n",
      "Train Epoch: 29 [0/4000 (0%)]\tLoss: 0.003847\n",
      "Train Epoch: 29 [1000/4000 (25%)]\tLoss: 0.005412\n",
      "Train Epoch: 29 [2000/4000 (50%)]\tLoss: 0.005786\n",
      "Train Epoch: 29 [3000/4000 (75%)]\tLoss: 0.006635\n",
      "Test set: Average loss: 0.004490\n",
      "\n",
      "Train Epoch: 30 [0/4000 (0%)]\tLoss: 0.003894\n",
      "Train Epoch: 30 [1000/4000 (25%)]\tLoss: 0.005435\n",
      "Train Epoch: 30 [2000/4000 (50%)]\tLoss: 0.005691\n",
      "Train Epoch: 30 [3000/4000 (75%)]\tLoss: 0.006622\n",
      "Test set: Average loss: 0.004492\n",
      "\n",
      "Train Epoch: 31 [0/4000 (0%)]\tLoss: 0.003934\n",
      "Train Epoch: 31 [1000/4000 (25%)]\tLoss: 0.005460\n",
      "Train Epoch: 31 [2000/4000 (50%)]\tLoss: 0.005609\n",
      "Train Epoch: 31 [3000/4000 (75%)]\tLoss: 0.006573\n",
      "Test set: Average loss: 0.004490\n",
      "\n",
      "Train Epoch: 32 [0/4000 (0%)]\tLoss: 0.003958\n",
      "Train Epoch: 32 [1000/4000 (25%)]\tLoss: 0.005485\n",
      "Train Epoch: 32 [2000/4000 (50%)]\tLoss: 0.005551\n",
      "Train Epoch: 32 [3000/4000 (75%)]\tLoss: 0.006553\n",
      "Test set: Average loss: 0.004499\n",
      "\n",
      "Train Epoch: 33 [0/4000 (0%)]\tLoss: 0.004015\n",
      "Train Epoch: 33 [1000/4000 (25%)]\tLoss: 0.005488\n",
      "Train Epoch: 33 [2000/4000 (50%)]\tLoss: 0.005553\n",
      "Train Epoch: 33 [3000/4000 (75%)]\tLoss: 0.006541\n",
      "Test set: Average loss: 0.004504\n",
      "\n",
      "Train Epoch: 34 [0/4000 (0%)]\tLoss: 0.004044\n",
      "Train Epoch: 34 [1000/4000 (25%)]\tLoss: 0.005508\n",
      "Train Epoch: 34 [2000/4000 (50%)]\tLoss: 0.005514\n",
      "Train Epoch: 34 [3000/4000 (75%)]\tLoss: 0.006432\n",
      "Test set: Average loss: 0.004486\n",
      "\n",
      "Train Epoch: 35 [0/4000 (0%)]\tLoss: 0.004042\n",
      "Train Epoch: 35 [1000/4000 (25%)]\tLoss: 0.005520\n",
      "Train Epoch: 35 [2000/4000 (50%)]\tLoss: 0.005480\n",
      "Train Epoch: 35 [3000/4000 (75%)]\tLoss: 0.006415\n",
      "Test set: Average loss: 0.004486\n",
      "\n",
      "Train Epoch: 36 [0/4000 (0%)]\tLoss: 0.004059\n",
      "Train Epoch: 36 [1000/4000 (25%)]\tLoss: 0.005505\n",
      "Train Epoch: 36 [2000/4000 (50%)]\tLoss: 0.005447\n",
      "Train Epoch: 36 [3000/4000 (75%)]\tLoss: 0.006399\n",
      "Test set: Average loss: 0.004507\n",
      "\n",
      "Train Epoch: 37 [0/4000 (0%)]\tLoss: 0.004082\n",
      "Train Epoch: 37 [1000/4000 (25%)]\tLoss: 0.005484\n",
      "Train Epoch: 37 [2000/4000 (50%)]\tLoss: 0.005445\n",
      "Train Epoch: 37 [3000/4000 (75%)]\tLoss: 0.006405\n",
      "Test set: Average loss: 0.004505\n",
      "\n",
      "Train Epoch: 38 [0/4000 (0%)]\tLoss: 0.004087\n",
      "Train Epoch: 38 [1000/4000 (25%)]\tLoss: 0.005441\n",
      "Train Epoch: 38 [2000/4000 (50%)]\tLoss: 0.005398\n",
      "Train Epoch: 38 [3000/4000 (75%)]\tLoss: 0.006398\n",
      "Test set: Average loss: 0.004517\n",
      "\n",
      "Train Epoch: 39 [0/4000 (0%)]\tLoss: 0.004113\n",
      "Train Epoch: 39 [1000/4000 (25%)]\tLoss: 0.005443\n",
      "Train Epoch: 39 [2000/4000 (50%)]\tLoss: 0.005398\n",
      "Train Epoch: 39 [3000/4000 (75%)]\tLoss: 0.006414\n",
      "Test set: Average loss: 0.004515\n",
      "\n",
      "Train Epoch: 40 [0/4000 (0%)]\tLoss: 0.004123\n",
      "Train Epoch: 40 [1000/4000 (25%)]\tLoss: 0.005452\n",
      "Train Epoch: 40 [2000/4000 (50%)]\tLoss: 0.005384\n",
      "Train Epoch: 40 [3000/4000 (75%)]\tLoss: 0.006232\n",
      "Test set: Average loss: 0.004517\n",
      "\n",
      "Train Epoch: 41 [0/4000 (0%)]\tLoss: 0.004128\n",
      "Train Epoch: 41 [1000/4000 (25%)]\tLoss: 0.005466\n",
      "Train Epoch: 41 [2000/4000 (50%)]\tLoss: 0.005367\n",
      "Train Epoch: 41 [3000/4000 (75%)]\tLoss: 0.006239\n",
      "Test set: Average loss: 0.004528\n",
      "\n",
      "Train Epoch: 42 [0/4000 (0%)]\tLoss: 0.004136\n",
      "Train Epoch: 42 [1000/4000 (25%)]\tLoss: 0.005477\n",
      "Train Epoch: 42 [2000/4000 (50%)]\tLoss: 0.005340\n",
      "Train Epoch: 42 [3000/4000 (75%)]\tLoss: 0.006255\n",
      "Test set: Average loss: 0.004526\n",
      "\n",
      "Train Epoch: 43 [0/4000 (0%)]\tLoss: 0.004133\n",
      "Train Epoch: 43 [1000/4000 (25%)]\tLoss: 0.005493\n",
      "Train Epoch: 43 [2000/4000 (50%)]\tLoss: 0.005327\n",
      "Train Epoch: 43 [3000/4000 (75%)]\tLoss: 0.006265\n",
      "Test set: Average loss: 0.004502\n",
      "\n",
      "Train Epoch: 44 [0/4000 (0%)]\tLoss: 0.004101\n",
      "Train Epoch: 44 [1000/4000 (25%)]\tLoss: 0.005501\n",
      "Train Epoch: 44 [2000/4000 (50%)]\tLoss: 0.005306\n",
      "Train Epoch: 44 [3000/4000 (75%)]\tLoss: 0.006281\n",
      "Test set: Average loss: 0.004495\n",
      "\n",
      "Train Epoch: 45 [0/4000 (0%)]\tLoss: 0.004096\n",
      "Train Epoch: 45 [1000/4000 (25%)]\tLoss: 0.005511\n",
      "Train Epoch: 45 [2000/4000 (50%)]\tLoss: 0.005346\n",
      "Train Epoch: 45 [3000/4000 (75%)]\tLoss: 0.006304\n",
      "Test set: Average loss: 0.004501\n",
      "\n",
      "Train Epoch: 46 [0/4000 (0%)]\tLoss: 0.004115\n",
      "Train Epoch: 46 [1000/4000 (25%)]\tLoss: 0.005523\n",
      "Train Epoch: 46 [2000/4000 (50%)]\tLoss: 0.005329\n",
      "Train Epoch: 46 [3000/4000 (75%)]\tLoss: 0.006286\n",
      "Test set: Average loss: 0.004501\n",
      "\n",
      "Train Epoch: 47 [0/4000 (0%)]\tLoss: 0.004121\n",
      "Train Epoch: 47 [1000/4000 (25%)]\tLoss: 0.005530\n",
      "Train Epoch: 47 [2000/4000 (50%)]\tLoss: 0.005265\n",
      "Train Epoch: 47 [3000/4000 (75%)]\tLoss: 0.006269\n",
      "Test set: Average loss: 0.004503\n",
      "\n",
      "Train Epoch: 48 [0/4000 (0%)]\tLoss: 0.004129\n",
      "Train Epoch: 48 [1000/4000 (25%)]\tLoss: 0.005537\n",
      "Train Epoch: 48 [2000/4000 (50%)]\tLoss: 0.005254\n",
      "Train Epoch: 48 [3000/4000 (75%)]\tLoss: 0.006263\n",
      "Test set: Average loss: 0.004505\n",
      "\n",
      "Train Epoch: 49 [0/4000 (0%)]\tLoss: 0.004131\n",
      "Train Epoch: 49 [1000/4000 (25%)]\tLoss: 0.005546\n",
      "Train Epoch: 49 [2000/4000 (50%)]\tLoss: 0.005244\n",
      "Train Epoch: 49 [3000/4000 (75%)]\tLoss: 0.006310\n",
      "Test set: Average loss: 0.004502\n",
      "\n",
      "Train Epoch: 50 [0/4000 (0%)]\tLoss: 0.004128\n",
      "Train Epoch: 50 [1000/4000 (25%)]\tLoss: 0.005555\n",
      "Train Epoch: 50 [2000/4000 (50%)]\tLoss: 0.005239\n",
      "Train Epoch: 50 [3000/4000 (75%)]\tLoss: 0.006307\n",
      "Test set: Average loss: 0.004502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "for epoch in range(1, 50 + 1):\n",
    "    train(net, device, train_loader, optimizer, epoch)\n",
    "    test(net, device, test_loader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "crazy-adaptation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 0.004129\n",
      "Train Epoch: 1 [1000/4000 (25%)]\tLoss: 0.005671\n",
      "Train Epoch: 1 [2000/4000 (50%)]\tLoss: 0.005244\n",
      "Train Epoch: 1 [3000/4000 (75%)]\tLoss: 0.005057\n",
      "Test set: Average loss: 0.004290\n",
      "\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 0.003724\n",
      "Train Epoch: 2 [1000/4000 (25%)]\tLoss: 0.005875\n",
      "Train Epoch: 2 [2000/4000 (50%)]\tLoss: 0.005224\n",
      "Train Epoch: 2 [3000/4000 (75%)]\tLoss: 0.005047\n",
      "Test set: Average loss: 0.004285\n",
      "\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 0.003713\n",
      "Train Epoch: 3 [1000/4000 (25%)]\tLoss: 0.005846\n",
      "Train Epoch: 3 [2000/4000 (50%)]\tLoss: 0.005229\n",
      "Train Epoch: 3 [3000/4000 (75%)]\tLoss: 0.005048\n",
      "Test set: Average loss: 0.004283\n",
      "\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 0.003713\n",
      "Train Epoch: 4 [1000/4000 (25%)]\tLoss: 0.005831\n",
      "Train Epoch: 4 [2000/4000 (50%)]\tLoss: 0.005233\n",
      "Train Epoch: 4 [3000/4000 (75%)]\tLoss: 0.005049\n",
      "Test set: Average loss: 0.004282\n",
      "\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 0.003712\n",
      "Train Epoch: 5 [1000/4000 (25%)]\tLoss: 0.005823\n",
      "Train Epoch: 5 [2000/4000 (50%)]\tLoss: 0.005236\n",
      "Train Epoch: 5 [3000/4000 (75%)]\tLoss: 0.005049\n",
      "Test set: Average loss: 0.004281\n",
      "\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 0.003712\n",
      "Train Epoch: 6 [1000/4000 (25%)]\tLoss: 0.005818\n",
      "Train Epoch: 6 [2000/4000 (50%)]\tLoss: 0.005238\n",
      "Train Epoch: 6 [3000/4000 (75%)]\tLoss: 0.005049\n",
      "Test set: Average loss: 0.004280\n",
      "\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 0.003711\n",
      "Train Epoch: 7 [1000/4000 (25%)]\tLoss: 0.005814\n",
      "Train Epoch: 7 [2000/4000 (50%)]\tLoss: 0.005240\n",
      "Train Epoch: 7 [3000/4000 (75%)]\tLoss: 0.005050\n",
      "Test set: Average loss: 0.004279\n",
      "\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 0.003710\n",
      "Train Epoch: 8 [1000/4000 (25%)]\tLoss: 0.005811\n",
      "Train Epoch: 8 [2000/4000 (50%)]\tLoss: 0.005241\n",
      "Train Epoch: 8 [3000/4000 (75%)]\tLoss: 0.005050\n",
      "Test set: Average loss: 0.004280\n",
      "\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 0.003710\n",
      "Train Epoch: 9 [1000/4000 (25%)]\tLoss: 0.005810\n",
      "Train Epoch: 9 [2000/4000 (50%)]\tLoss: 0.005244\n",
      "Train Epoch: 9 [3000/4000 (75%)]\tLoss: 0.005050\n",
      "Test set: Average loss: 0.004279\n",
      "\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 0.003710\n",
      "Train Epoch: 10 [1000/4000 (25%)]\tLoss: 0.005807\n",
      "Train Epoch: 10 [2000/4000 (50%)]\tLoss: 0.005247\n",
      "Train Epoch: 10 [3000/4000 (75%)]\tLoss: 0.005052\n",
      "Test set: Average loss: 0.004279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "for epoch in range(1, 10 + 1):\n",
    "    train(net, device, train_loader, optimizer, epoch)\n",
    "    test(net, device, test_loader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "consistent-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_sat = nn.Sequential(\n",
    "    *net,\n",
    "    SatModule(mpc_controller.variable_size(), mpc_controller.u_min, mpc_controller.u_max)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cross-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'state_dict': net_sat.state_dict()}, 'dc_dc_converter_qp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "delayed-buying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = torch.load('dc_dc_converter_qp.pt')\n",
    "net_sat.load_state_dict(saved_model['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "amazing-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_net = np.vstack((x.flatten(), y.flatten())).T\n",
    "z_net = net_sat(torch.from_numpy(z_net).float())\n",
    "z_net = z_net.detach().cpu().numpy()\n",
    "z_net = z_net.reshape(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "foreign-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 122.04x75.4249 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cs = ax.contourf(x, y, z_net, levels=100)\n",
    "for c in cs.collections:\n",
    "    c.set_edgecolor('face')\n",
    "fig.colorbar(cs, ticks=[0, 0.25, 0.5, 0.75, 1])\n",
    "ax.set_title('Simplified Controller')\n",
    "ax.set_xlabel(r'$i_L$')\n",
    "ax.set_ylabel(r'$v_O$')\n",
    "plt.savefig('figures/simplified.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "precious-secondary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 122.04x75.4249 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cs = ax.contourf(x, y, np.abs(z_opt - z_net), levels=100)\n",
    "for c in cs.collections:\n",
    "    c.set_edgecolor('face')\n",
    "fig.colorbar(cs, ticks=[0, 0.25, 0.5, 0.75, 1])\n",
    "ax.set_title('Approximation Error')\n",
    "ax.set_xlabel(r'$i_L$')\n",
    "ax.set_ylabel(r'$v_O$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "atlantic-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier = Verifier(parameter_set, mpc_controller, net_sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "surface-fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QP Ineq Bound: 100%|██████████| 68/68 [00:01<00:00, 47.70it/s]\n",
      "QP Dual Bound: 100%|██████████| 68/68 [00:10<00:00,  6.71it/s]\n",
      "QP Output Bound: 100%|██████████| 1/1 [00:00<00:00, 57.52it/s]\n",
      "QP Ineq Bound: 100%|██████████| 3/3 [00:00<00:00, 369.55it/s]\n",
      "QP Dual Bound: 100%|██████████| 3/3 [00:00<00:00, 369.28it/s]\n",
      "QP Output Bound: 100%|██████████| 3/3 [00:00<00:00, 260.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Bounds:\n",
      "lower bound: [0.]\n",
      "upper bound: [1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mpc_bounds, net_bounds = verifier.compute_bounds(method=BoundArithmetic.ZONO_ARITHMETIC, mip=True)\n",
    "print('Neural Network Bounds:')\n",
    "print(f'lower bound: {net_bounds[\"lb\"]}')\n",
    "print(f'upper bound: {net_bounds[\"ub\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "breeding-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.0 build v9.5.0rc5 (mac64[x86])\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "Optimize a model with 359 rows, 302 columns and 808 nonzeros\n",
      "Model fingerprint: 0xc872c159\n",
      "Model has 148 general constraints\n",
      "Variable types: 229 continuous, 73 integer (73 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-04, 3e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [8e-02, 1e+02]\n",
      "  RHS range        [7e-18, 1e+02]\n",
      "  GenCon rhs range [7e-18, 7e+00]\n",
      "  GenCon coe range [7e-02, 1e+00]\n",
      "\n",
      "User MIP start produced solution with objective 0.130974 (0.01s)\n",
      "Loaded user MIP start with objective 0.130974\n",
      "\n",
      "Presolve removed 256 rows and 187 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 103 rows, 115 columns, 362 nonzeros\n",
      "Presolved model has 14 SOS constraint(s)\n",
      "Variable types: 83 continuous, 32 integer (32 binary)\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 99 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   11    0.13097    1.00000   664%     -    0s\n",
      "     0     0    1.00000    0   13    0.13097    1.00000   664%     -    0s\n",
      "     0     0    1.00000    0   12    0.13097    1.00000   664%     -    0s\n",
      "     0     0    1.00000    0   11    0.13097    1.00000   664%     -    0s\n",
      "     0     0    1.00000    0   12    0.13097    1.00000   664%     -    0s\n",
      "H    0     0                       0.1465873    1.00000   582%     -    0s\n",
      "     0     0    1.00000    0   11    0.14659    1.00000   582%     -    0s\n",
      "     0     0    1.00000    0   11    0.14659    1.00000   582%     -    0s\n",
      "H    0     0                       0.1478310    1.00000   576%     -    0s\n",
      "     0     0    1.00000    0   10    0.14783    1.00000   576%     -    0s\n",
      "     0     0    1.00000    0   10    0.14783    1.00000   576%     -    0s\n",
      "     0     2    1.00000    0   10    0.14783    1.00000   576%     -    0s\n",
      "H   15    15                       0.2428093    0.97259   301%  18.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Learned: 1\n",
      "  Implied bound: 14\n",
      "  MIR: 2\n",
      "  Flow cover: 4\n",
      "  Relax-and-lift: 1\n",
      "\n",
      "Explored 66 nodes (928 simplex iterations) in 0.10 seconds (0.04 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 4: 0.242809 0.147831 0.146587 0.130974 \n",
      "No other solutions better than 0.242809\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.428092584416e-01, best bound 2.428092584416e-01, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "bound, parameters = verifier.find_max_abs_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "persistent-inflation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum absolute Error Bound between MPC and NN: 0.24280925844159973 at [0.0, 6.787028776081563]\n",
      "Double Checking by calulcaing error at this position: 0.24280926418079096\n"
     ]
    }
   ],
   "source": [
    "print(f'Maximum absolute Error Bound between MPC and NN: {bound} at {parameters}')\n",
    "u0_mpc = mpc_controller.solve(np.array(parameters))[mpc_controller.u0][0]\n",
    "u0_net = net_sat(torch.from_numpy(np.array(parameters)).float()).detach().numpy()[0]\n",
    "print(f'Double Checking by calulcaing error at this position: {u0_mpc - u0_net}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "featured-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 122.04x75.4249 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cs = ax.contourf(x, y, np.abs(z_opt - z_net), levels=100)\n",
    "for c in cs.collections:\n",
    "    c.set_edgecolor('face')\n",
    "ax.plot(parameters[0], parameters[1], 'ro', markersize=2)\n",
    "fig.colorbar(cs, ticks=[0, 0.1, 0.2])\n",
    "ax.set_title('Approximation Error')\n",
    "ax.set_xlabel(r'$i_L$')\n",
    "ax.set_ylabel(r'$v_O$')\n",
    "plt.savefig('figures/approx_error.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bacterial-techno",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QP Ineq Bound: 100%|██████████| 68/68 [00:00<00:00, 647.57it/s]\n",
      "QP Dual Bound: 100%|██████████| 68/68 [00:00<00:00, 4608.68it/s]\n",
      "QP Output Bound: 100%|██████████| 1/1 [00:00<00:00, 283.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter NonConvex to value 2\n",
      "Gurobi Optimizer version 9.5.0 build v9.5.0rc5 (mac64[x86])\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "Optimize a model with 429 rows, 361 columns and 959 nonzeros\n",
      "Model fingerprint: 0x98cd9087\n",
      "Model has 63 quadratic objective terms\n",
      "Model has 146 general constraints\n",
      "Variable types: 288 continuous, 73 integer (73 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-04, 3e+02]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [2e+00, 3e+02]\n",
      "  Bounds range     [8e-02, 7e+00]\n",
      "  RHS range        [7e-18, 7e+00]\n",
      "  GenCon rhs range [7e-18, 7e+00]\n",
      "  GenCon coe range [7e-02, 1e+00]\n",
      "\n",
      "User MIP start produced solution with objective 2.53533 (0.08s)\n",
      "User MIP start produced solution with objective 1.35714 (0.09s)\n",
      "Loaded user MIP start with objective 1.35714\n",
      "\n",
      "Presolve removed 290 rows and 177 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 173 rows, 248 columns, 618 nonzeros\n",
      "Presolved model has 45 SOS constraint(s)\n",
      "Presolved model has 32 quadratic constraint(s)\n",
      "Presolved model has 31 bilinear constraint(s)\n",
      "Variable types: 199 continuous, 49 integer (49 binary)\n",
      "\n",
      "Root relaxation: objective -1.677561e+02, 175 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 -167.75611    0   26    1.35714 -167.75611      -     -    0s\n",
      "     0     0 -127.91445    0   31    1.35714 -127.91445  9525%     -    0s\n",
      "     0     0 -122.16259    0   35    1.35714 -122.16259  9101%     -    0s\n",
      "     0     0  -89.86486    0   37    1.35714  -89.86486  6722%     -    0s\n",
      "     0     0  -89.79144    0   37    1.35714  -89.79144  6716%     -    0s\n",
      "     0     0  -85.20279    0   41    1.35714  -85.20279  6378%     -    0s\n",
      "     0     0  -85.10596    0   42    1.35714  -85.10596  6371%     -    0s\n",
      "     0     0  -84.48712    0   42    1.35714  -84.48712  6325%     -    0s\n",
      "     0     0  -84.44759    0   42    1.35714  -84.44759  6322%     -    0s\n",
      "     0     0  -84.21924    0   42    1.35714  -84.21924  6306%     -    0s\n",
      "     0     0  -84.21763    0   42    1.35714  -84.21763  6306%     -    0s\n",
      "     0     0  -84.12268    0   41    1.35714  -84.12268  6299%     -    0s\n",
      "     0     0  -84.10071    0   41    1.35714  -84.10071  6297%     -    0s\n",
      "     0     0  -84.09027    0   41    1.35714  -84.09027  6296%     -    0s\n",
      "H    0     0                       0.9888795  -84.09027  8604%     -    0s\n",
      "     0     2  -84.09027    0   41    0.98888  -84.09027  8604%     -    0s\n",
      "H 1082   118                       0.7488682  -68.65937  9268%  34.4    0s\n",
      "H 1207   128                       0.7488679  -67.19807  9073%  35.1    0s\n",
      "H 1547   164                       0.7488676  -66.42645  8970%  36.3    0s\n",
      "H 1718   168                       0.4030791  -62.89862      -  36.0    0s\n",
      "H 1853   182                       0.4030787  -62.89862      -  35.5    0s\n",
      "H 1884   182                       0.4030787  -62.89862      -  35.1    0s\n",
      "H 2588   186                       0.4030787  -37.32968  9361%  33.8    1s\n",
      "H 2591   178                       0.4030787  -37.32968  9361%  33.8    1s\n",
      "H 2595   171                       0.4030787  -37.32968  9361%  33.7    1s\n",
      "H 2685   189                       0.4030787  -37.32968  9361%  35.0    1s\n",
      "H 3694   128                       0.4030787  -37.32968  9361%  37.7    2s\n",
      "H 4819   151                       0.0280286  -37.32968      -  36.6    3s\n",
      "H 5023   153                       0.0280285  -37.32968      -  36.4    3s\n",
      "H 5224   161                       0.0054497  -37.32968      -  36.2    3s\n",
      "H 6887   178                       0.0054496  -37.32968      -  33.8    4s\n",
      "  9655   290   -0.00582   88   30    0.00545   -9.54138      -  27.1    5s\n",
      "*13876  1227             123       0.0028368   -0.95868      -  21.2    6s\n",
      " 27749  1555    0.00012  105   24    0.00284   -0.04764  1779%  13.9   10s\n",
      "*29618  1226             104       0.0001519   -0.01319  8778%  13.7   11s\n",
      "*30524   811             110       0.0001500   -0.01007  6811%  13.5   11s\n",
      "*32151   819             103       0.0000337   -0.00544      -  13.5   13s\n",
      " 35887   862    0.00001  100   21    0.00003   -0.00013   474%  13.5   15s\n",
      "*37146  1090             101       0.0000210   -0.00008   505%  13.1   15s\n",
      "*37149  1090             101       0.0000209   -0.00008   507%  13.1   15s\n",
      "*38317  1045             104       0.0000201   -0.00002   190%  12.9   15s\n",
      "*38324  1045             105       0.0000200   -0.00002   191%  12.9   15s\n",
      "*39840   511             104       0.0000200    0.00001  73.4%  12.6   16s\n",
      "*39912   520             102       0.0000199    0.00001  66.9%  12.6   16s\n",
      "*39915   521             102       0.0000199    0.00001  66.8%  12.6   16s\n",
      "*40157   534             103       0.0000196    0.00001  59.4%  12.5   16s\n",
      "*40276   534             101       0.0000196    0.00001  58.8%  12.5   16s\n",
      "*40497   535             105       0.0000195    0.00001  54.8%  12.5   16s\n",
      "*41040   555             104       0.0000195    0.00001  25.4%  12.4   16s\n",
      "*41206     4             103       0.0000194    0.00002  21.5%  12.3   16s\n",
      "*41408     5             101       0.0000193    0.00002  18.1%  12.3   16s\n",
      "*41787     1             101       0.0000193    0.00002  0.01%  12.2   16s\n",
      "*41788     0             104       0.0000193    0.00002  0.00%  12.2   16s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  MIR: 2\n",
      "  Flow cover: 2\n",
      "  RLT: 23\n",
      "  PSD: 1\n",
      "\n",
      "Explored 41789 nodes (510917 simplex iterations) in 16.52 seconds (9.90 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 1.92562e-05 1.92582e-05 1.93254e-05 ... 1.99027e-05\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.121949300132e-05, best bound 1.925622639634e-05, gap 9.2522%\n"
     ]
    }
   ],
   "source": [
    "bound, parameters = verifier.verify_stability(guess=mpc_controller.xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "willing-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stability bound: 1.9256226396339674e-05 at [0.04965736392747466, 4.998314946864348], should be >=0 for stability\n"
     ]
    }
   ],
   "source": [
    "print(f'Stability bound: {bound} at {parameters}, should be >=0 for stability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-courage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
